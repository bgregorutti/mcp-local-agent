# USAGE STATISTICS
REMOTE_INPUT_COST_PER_1K=0.003
REMOTE_OUTPUT_COST_PER_1K=0.015
LOCAL_COST_PER_1K=0.0

# LOCAL LLM SETTINGS
LOCAL_LLM=qwen2.5-coder-7b-instruct-mlx
BACKEND_TYPE=lmstudio # or ollama
BACKEND_URL=http://localhost:1234/v1 # or http://localhost:11434/v1 for ollama


